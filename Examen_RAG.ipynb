{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain_google_genai langchain_community pymupdf faiss_cpu\n",
        "!pip install \"unstructured[pdf]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A1B7q4RWNdWw",
        "outputId": "6059a8d0-8f84-4444-e7c7-446f9eef8263"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting faiss_cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.16-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.41)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.10.6)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.11)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss_cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.24.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.25.6)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain_community) (0.3.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.69.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.11-py3-none-any.whl (39 kB)\n",
            "Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.16-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pymupdf, mypy-extensions, marshmallow, httpx-sse, faiss_cpu, typing-inspect, pydantic-settings, dataclasses-json, google-ai-generativelanguage, langchain_google_genai, langchain_community\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 faiss_cpu-1.10.0 filetype-1.2.0 google-ai-generativelanguage-0.6.16 httpx-sse-0.4.0 langchain_community-0.3.19 langchain_google_genai-2.0.11 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 pymupdf-1.25.3 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "112cb87380314dcd8b6242df52ecaa7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured[pdf]\n",
            "  Downloading unstructured-0.16.25-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (1.2.0)\n",
            "Collecting python-magic (from unstructured[pdf])\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (5.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (4.13.3)\n",
            "Collecting emoji (from unstructured[pdf])\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured[pdf])\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured[pdf])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (1.26.4)\n",
            "Collecting rapidfuzz (from unstructured[pdf])\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured[pdf])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured[pdf])\n",
            "  Downloading unstructured_client-0.31.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (1.17.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured[pdf])\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured[pdf]) (1.1)\n",
            "Collecting onnx (from unstructured[pdf])\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting pdf2image (from unstructured[pdf])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pikepdf (from unstructured[pdf])\n",
            "  Downloading pikepdf-9.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting pi-heif (from unstructured[pdf])\n",
            "  Downloading pi_heif-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pypdf (from unstructured[pdf])\n",
            "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting google-cloud-vision (from unstructured[pdf])\n",
            "  Downloading google_cloud_vision-3.10.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting effdet (from unstructured[pdf])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting unstructured-inference>=0.8.7 (from unstructured[pdf])\n",
            "  Downloading unstructured_inference-0.8.9-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
            "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting python-multipart (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (0.28.1)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (4.11.0.86)\n",
            "Collecting onnxruntime>=1.17.0 (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (2.5.1+cu124)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (1.0.15)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (4.48.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from unstructured-inference>=0.8.7->unstructured[pdf]) (1.13.1)\n",
            "Collecting pypdfium2 (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (11.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured[pdf]) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured[pdf]) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[pdf]) (0.20.1+cu124)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from effdet->unstructured[pdf]) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->unstructured[pdf])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (2.24.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[pdf]) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[pdf]) (4.25.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[pdf]) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured[pdf]) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[pdf]) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[pdf]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured[pdf]) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[pdf]) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[pdf]) (43.0.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from pikepdf->unstructured[pdf]) (1.2.18)\n",
            "Collecting olefile (from python-oxmsg->unstructured[pdf])\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured[pdf]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured[pdf]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured[pdf]) (2025.1.31)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured[pdf])\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured[pdf])\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[pdf]) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[pdf]) (2.10.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Collecting typing-inspection>=0.4.0 (from unstructured-client->unstructured[pdf])\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.69.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[pdf])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf]) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf]) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.7->unstructured[pdf]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.7->unstructured[pdf]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.7->unstructured[pdf]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.7->unstructured[pdf]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->unstructured-inference>=0.8.7->unstructured[pdf]) (3.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->unstructured-client->unstructured[pdf]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->unstructured-client->unstructured[pdf]) (2.27.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->unstructured-inference>=0.8.7->unstructured[pdf]) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->unstructured-inference>=0.8.7->unstructured[pdf]) (0.21.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured-inference>=0.8.7->unstructured[pdf]) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured-inference>=0.8.7->unstructured[pdf]) (2025.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->unstructured-inference>=0.8.7->unstructured[pdf]) (3.0.2)\n",
            "Downloading unstructured_inference-0.8.9-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_vision-3.10.0-py2.py3-none-any.whl (523 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m523.4/523.4 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured-0.16.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.31.1-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, antlr4-python3-runtime\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=bc4c568566f0bf17845813032ab11ad5db231eb294d4c18a94ceb42ea4012632\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2509b1eacf0814f2910833997e8613df6203d2de5b3ca7eabc6150f8ac79cd3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built langdetect antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, unstructured.pytesseract, typing-inspection, rapidfuzz, python-multipart, python-magic, python-iso639, pypdfium2, pypdf, pi-heif, pdf2image, onnx, omegaconf, olefile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, humanfriendly, eval-type-backport, emoji, backoff, aiofiles, python-oxmsg, pikepdf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, unstructured-client, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, unstructured, google-cloud-vision, unstructured-inference, effdet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-24.1.0 antlr4-python3-runtime-4.9.3 backoff-2.2.1 coloredlogs-15.0.1 effdet-0.4.1 emoji-2.14.1 eval-type-backport-0.2.2 google-cloud-vision-3.10.0 humanfriendly-10.0 langdetect-1.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 olefile-0.47 omegaconf-2.3.0 onnx-1.17.0 onnxruntime-1.21.0 pdf2image-1.17.0 pdfminer.six-20240706 pi-heif-0.21.0 pikepdf-9.5.2 pypdf-5.3.1 pypdfium2-4.30.1 python-iso639-2025.2.18 python-magic-0.4.27 python-multipart-0.0.20 python-oxmsg-0.0.2 rapidfuzz-3.12.2 typing-inspection-0.4.0 unstructured-0.16.25 unstructured-client-0.31.1 unstructured-inference-0.8.9 unstructured.pytesseract-0.3.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pydevd_plugins"
                ]
              },
              "id": "c7fc81e6cb2b4ff9a098c39cb8f05f0b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99mZEBASQO_c",
        "outputId": "cfdec33e-5440-473e-a9de-ef797694662a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b41KOUU5Na6i"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkr37ZJvNa6k"
      },
      "source": [
        "Les modèles de langage de grande taille (LLM, pour Large Language Models) comme GPT-3, BERT, et T5 ont révolutionné le domaine du traitement du langage naturel (NLP). Ces modèles sont capables de générer du texte, de répondre à des questions, de traduire des langues, et bien plus encore. Cependant, ils ont des limites, notamment en ce qui concerne l'accès à des informations précises et à jour, ainsi que leur capacité à raisonner sur des connaissances externes.\n",
        "\n",
        "C'est là que les modèles RAG (Retrieval-Augmented Generation) entrent en jeu. RAG combine la puissance des LLM avec un mécanisme de recherche (retrieval) pour accéder à des informations externes, ce qui permet d'améliorer la qualité et la précision des réponses générées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfdIuDLCNa6o"
      },
      "source": [
        "## Architecture d'un RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfT_uWzkNa6q"
      },
      "source": [
        "L'architecture de RAG se compose de deux composants principaux :\n",
        "\n",
        "- Le module de recherche (Retriever)\n",
        "- Le module de génération (Generator)\n",
        "\n",
        "Chacun de ces modules joue un rôle crucial dans le processus de génération de texte. Examinons-les en détail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK2kbwHYNa6r"
      },
      "source": [
        "### Prétraitement des Données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmbEBK-ENa6t"
      },
      "source": [
        "Extraire le texte des documents (PDF, Word, txt, etc.) et le préparer.\n",
        "\n",
        "Outils utilisés :\n",
        "- PyMuPDF pour extraire le texte des PDFs.\n",
        "- Text Splitters pour diviser le texte en chunks (blocs de texte) utilisables par le modèle."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Charger un PDF\n",
        "# pdf_file_path = \"/content/drive/MyDrive/MES COURS/L3/ChatBot/LLM/corpus/Copie de Rapport_groupe1_DEVOPS.pdf\"\n",
        "# loader = PyMuPDFLoader(pdf_file_path)\n",
        "# documents = loader.load()\n",
        "\n",
        "# Charger un directory\n",
        "\n",
        "# =====================================================\n",
        "\n",
        "# directory_path = \"/content/drive/MyDrive/MES_COURS/L3/ChatBot/EXAM_RAG/corpus\"\n",
        "# # Pass 'glob' during initialization\n",
        "# loader = DirectoryLoader(directory_path, exclude=[\"*.pdf\"], show_progress=True)\n",
        "# # Call load without arguments\n",
        "# documents = loader.load()\n",
        "# documents"
      ],
      "metadata": {
        "id": "be80sdkireav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Charger tous les fichiers correctement"
      ],
      "metadata": {
        "id": "Rze5IX7uBNHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "directory_path = \"/content/drive/MyDrive/MES_COURS/L3/ChatBot/EXAM_RAG/corpus\"\n",
        "\n",
        "loader = DirectoryLoader(directory_path, glob=\"*.pdf\", show_progress=True)\n",
        "documents = loader.load()\n",
        "\n",
        "print(f\"Nombre de documents chargés : {len(documents)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZcdYA9Qg_gd",
        "outputId": "c4603810-9fe9-45c3-e5cf-906747944058"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [02:17<00:00,  5.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de documents chargés : 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation efficace du texte"
      ],
      "metadata": {
        "id": "WC_vdXpRBidP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=600,  # Augmenter la taille des morceaux pour une meilleure compréhension\n",
        "    chunk_overlap=150\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"🔹 Nombre total de chunks : {len(chunks)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN0QqKJ0Bhi0",
        "outputId": "c37fce68-ae9e-4b10-9ddd-55fcf514f961"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Nombre total de chunks : 1179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_owGFbWNa6t"
      },
      "outputs": [],
      "source": [
        "# # Découper le texte en petits morceaux\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "# chunks = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chunks[1].page_content"
      ],
      "metadata": {
        "id": "lmkkPM4rRblZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stockage dans FAISS avec l'Embedding Model"
      ],
      "metadata": {
        "id": "ZLXlptzdCM2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embedding_model_name = \"models/embedding-001\"\n",
        "API_KEY = \"AIzaSyDOFi3F068et2KSyo5aqoOSKUpN2Q65toA\"\n",
        "\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=embedding_model_name, google_api_key=API_KEY)\n",
        "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
        "\n",
        "print(\"Base de données vectorielle créée avec succès !\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG3fpcS8B8IL",
        "outputId": "c3da29bf-32ee-4348-acc9-5fb196aab56e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base de données vectorielle créée avec succès !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qar49kLSNa6u"
      },
      "source": [
        "Transformer chaque chunk en vecteur numérique et les stocker dans une base de données vectorielle.\n",
        "\n",
        "Outils utilisés :\n",
        "- Embeddings de Gemini ou OpenAI pour transformer le texte en vecteurs.\n",
        "- FAISS pour stocker et indexer ces vecteurs efficacement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1OPJHiaNa6v"
      },
      "outputs": [],
      "source": [
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "\n",
        "\n",
        "# # Convertir les chunks en vecteurs\n",
        "# embedding_model_name = \"models/embedding-001\"\n",
        "# API_KEY = \"AIzaSyDOFi3F068et2KSyo5aqoOSKUpN2Q65toA\"\n",
        "\n",
        "# embedding_model = GoogleGenerativeAIEmbeddings(model=embedding_model_name, google_api_key=API_KEY)\n",
        "# vector_store = FAISS.from_documents(chunks, embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "ISVQ047bTZhA",
        "outputId": "29e647b4-06ea-4652-d8c2-f68c8be14228"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_community.vectorstores.faiss.FAISS"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_community.vectorstores.faiss.FAISS</b><br/>def __init__(embedding_function: Union[Callable[[str], List[float]], Embeddings], index: Any, docstore: Docstore, index_to_docstore_id: Dict[int, str], relevance_score_fn: Optional[Callable[[float], float]]=None, normalize_L2: bool=False, distance_strategy: DistanceStrategy=DistanceStrategy.EUCLIDEAN_DISTANCE)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py</a>FAISS vector store integration.\n",
              "\n",
              "See [The FAISS Library](https://arxiv.org/pdf/2401.08281) paper.\n",
              "\n",
              "Setup:\n",
              "    Install ``langchain_community`` and ``faiss-cpu`` python packages.\n",
              "\n",
              "    .. code-block:: bash\n",
              "\n",
              "        pip install -qU langchain_community faiss-cpu\n",
              "\n",
              "Key init args — indexing params:\n",
              "    embedding_function: Embeddings\n",
              "        Embedding function to use.\n",
              "\n",
              "Key init args — client params:\n",
              "    index: Any\n",
              "        FAISS index to use.\n",
              "    docstore: Docstore\n",
              "        Docstore to use.\n",
              "    index_to_docstore_id: Dict[int, str]\n",
              "        Mapping of index to docstore id.\n",
              "\n",
              "Instantiate:\n",
              "    .. code-block:: python\n",
              "\n",
              "        import faiss\n",
              "        from langchain_community.vectorstores import FAISS\n",
              "        from langchain_community.docstore.in_memory import InMemoryDocstore\n",
              "        from langchain_openai import OpenAIEmbeddings\n",
              "\n",
              "        index = faiss.IndexFlatL2(len(OpenAIEmbeddings().embed_query(&quot;hello world&quot;)))\n",
              "\n",
              "        vector_store = FAISS(\n",
              "            embedding_function=OpenAIEmbeddings(),\n",
              "            index=index,\n",
              "            docstore= InMemoryDocstore(),\n",
              "            index_to_docstore_id={}\n",
              "        )\n",
              "\n",
              "Add Documents:\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.documents import Document\n",
              "\n",
              "        document_1 = Document(page_content=&quot;foo&quot;, metadata={&quot;baz&quot;: &quot;bar&quot;})\n",
              "        document_2 = Document(page_content=&quot;thud&quot;, metadata={&quot;bar&quot;: &quot;baz&quot;})\n",
              "        document_3 = Document(page_content=&quot;i will be deleted :(&quot;)\n",
              "\n",
              "        documents = [document_1, document_2, document_3]\n",
              "        ids = [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]\n",
              "        vector_store.add_documents(documents=documents, ids=ids)\n",
              "\n",
              "Delete Documents:\n",
              "    .. code-block:: python\n",
              "\n",
              "        vector_store.delete(ids=[&quot;3&quot;])\n",
              "\n",
              "Search:\n",
              "    .. code-block:: python\n",
              "\n",
              "        results = vector_store.similarity_search(query=&quot;thud&quot;,k=1)\n",
              "        for doc in results:\n",
              "            print(f&quot;* {doc.page_content} [{doc.metadata}]&quot;)\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        * thud [{&#x27;bar&#x27;: &#x27;baz&#x27;}]\n",
              "\n",
              "Search with filter:\n",
              "    .. code-block:: python\n",
              "\n",
              "        results = vector_store.similarity_search(query=&quot;thud&quot;,k=1,filter={&quot;bar&quot;: &quot;baz&quot;})\n",
              "        for doc in results:\n",
              "            print(f&quot;* {doc.page_content} [{doc.metadata}]&quot;)\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        * thud [{&#x27;bar&#x27;: &#x27;baz&#x27;}]\n",
              "\n",
              "Search with score:\n",
              "    .. code-block:: python\n",
              "\n",
              "        results = vector_store.similarity_search_with_score(query=&quot;qux&quot;,k=1)\n",
              "        for doc, score in results:\n",
              "            print(f&quot;* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]&quot;)\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        * [SIM=0.335304] foo [{&#x27;baz&#x27;: &#x27;bar&#x27;}]\n",
              "\n",
              "Async:\n",
              "    .. code-block:: python\n",
              "\n",
              "        # add documents\n",
              "        # await vector_store.aadd_documents(documents=documents, ids=ids)\n",
              "\n",
              "        # delete documents\n",
              "        # await vector_store.adelete(ids=[&quot;3&quot;])\n",
              "\n",
              "        # search\n",
              "        # results = vector_store.asimilarity_search(query=&quot;thud&quot;,k=1)\n",
              "\n",
              "        # search with score\n",
              "        results = await vector_store.asimilarity_search_with_score(query=&quot;qux&quot;,k=1)\n",
              "        for doc,score in results:\n",
              "            print(f&quot;* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]&quot;)\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        * [SIM=0.335304] foo [{&#x27;baz&#x27;: &#x27;bar&#x27;}]\n",
              "\n",
              "Use as Retriever:\n",
              "    .. code-block:: python\n",
              "\n",
              "        retriever = vector_store.as_retriever(\n",
              "            search_type=&quot;mmr&quot;,\n",
              "            search_kwargs={&quot;k&quot;: 1, &quot;fetch_k&quot;: 2, &quot;lambda_mult&quot;: 0.5},\n",
              "        )\n",
              "        retriever.invoke(&quot;thud&quot;)\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        [Document(metadata={&#x27;bar&#x27;: &#x27;baz&#x27;}, page_content=&#x27;thud&#x27;)]</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 75);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0xXfjHCNa6v"
      },
      "source": [
        "### 1. Le Module de Recherche (Retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UD0aUvuNa6v"
      },
      "source": [
        "Le module de recherche est responsable de la sélection de documents pertinents à partir d'une base de connaissances. Ce module est essentiel pour fournir au modèle des informations à jour et spécifiques au contexte de la requête."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS3AijYONa6w"
      },
      "source": [
        "**Fonctionnement du Retriever**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBkoW6enNa6w"
      },
      "source": [
        "1. **Embedding de la Question**:\n",
        "Conversion de la question en vecteur\n",
        "\n",
        "2. **Recherche de Similarité**:\n",
        "Calcul des distances (cosinus, euclidienne)\n",
        "\n",
        "3. **Sélection** des K documents les plus pertinents (K est un hyperparamètre)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requête globale sur tous les fichiers"
      ],
      "metadata": {
        "id": "YCxNANceCgZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"liste des Projets qui du portes par le 3fpt\"\n",
        "\n",
        "retrieved_docs = vector_store.similarity_search(query, k=5)  # Augmenter k pour plus de contexte\n",
        "\n",
        "# Afficher les documents récupérés\n",
        "for i, doc in enumerate(retrieved_docs, 1):\n",
        "    print(f\"Résultat {i} :\")\n",
        "    print(doc.page_content)\n",
        "    print(\"------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmMxYGCVCd0Z",
        "outputId": "c187cd73-943d-445f-fb36-8b181d7baf87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultat 1 :\n",
            "Fonds de Financement de la Formation professionnelle et technique\n",
            "\n",
            "professionnelle et technique\n",
            "\n",
            "120\n",
            "\n",
            "ZOOM SUR ZOOM SUR\n",
            "\n",
            "A la ﬁ n de l’année 2023, le 3FPT a poursuivi le ﬁ nancement de projets engagés de 2019 à 2023. Il s’agit de :\n",
            "\n",
            " 75 projets d’investissements (PI) et 2\n",
            "\n",
            "avenants sur contrats  30 plans stratégiques de développement (PSD)\n",
            "\n",
            " 82 projets de formation insertion (PFI) dont 27 avec investissements\n",
            "\n",
            " 23 projets de formation de\n",
            "\n",
            "formateurs\n",
            "\n",
            " 106 Contrats de Projets de\n",
            "\n",
            "Formation Qualiﬁ ante des jeunes\n",
            "\n",
            "\n",
            "------------------------\n",
            "Résultat 2 :\n",
            "Les activités visent l’augmentation du nombre de personnes disposant de qualifications pertinentes et de bonne qualité pour le marché du travail, ainsi que la promotion des services d’insertion professionnelle. Pour ce volet, le 3FPT doit former au moins 2600 jeunes sur une durée de 3 ans, répartis dans les zones couvertes par le projet.\n",
            "------------------------\n",
            "Résultat 3 :\n",
            "Les activités visent l’augmentation du nombre de personnes disposant de qualifications pertinentes et de bonne qualité pour le marché du travail, ainsi que la promotion des services d’insertion professionnelle. Pour ce volet, le 3FPT doit former au moins 2600 jeunes sur une durée de 3 ans, répartis dans les zones couvertes par le projet.\n",
            "------------------------\n",
            "Résultat 4 :\n",
            " Multimédia ;\n",
            "\n",
            " Administration de réseaux ;\n",
            "\n",
            " Tourisme et loisirs ;\n",
            "\n",
            " Métiers du rail ;\n",
            "\n",
            " Gestion et exploitation\n",
            "\n",
            "minières.\n",
            "\n",
            "2. SYNTHÈSE 2016-2023 DU 3FPT À THIÈS\n",
            "\n",
            "Année\n",
            "\n",
            "EOP\n",
            "\n",
            "Individus\n",
            "\n",
            "Investissement Montant FCFA\n",
            "\n",
            "2016-2021\n",
            "\n",
            "43 450\n",
            "\n",
            "31 571\n",
            "\n",
            "69\n",
            "\n",
            "21 953 060 574\n",
            "\n",
            "2022\n",
            "\n",
            "57 563\n",
            "\n",
            "6 232\n",
            "\n",
            "48\n",
            "\n",
            "9 210 530 842\n",
            "\n",
            "2023\n",
            "\n",
            "30 524\n",
            "\n",
            "13 791\n",
            "\n",
            "83\n",
            "\n",
            "9 021 040 142\n",
            "\n",
            "Total Dakar\n",
            "\n",
            "131 537\n",
            "\n",
            "51 594\n",
            "\n",
            "200\n",
            "\n",
            "40 184 631 558\n",
            "\n",
            "34\n",
            "\n",
            "Visite usine ELEMENTERRE - Projet JANG BAN - Gandigal (11 Mai 2023)\n",
            "\n",
            "3FPT\n",
            "\n",
            "Réalisations région de Thiès 2022-2023\n",
            "\n",
            "BILAN 2016-2023\n",
            "\n",
            "s s è è i i h h T T\n",
            "------------------------\n",
            "Résultat 5 :\n",
            "Le 3FPT a aussi fait preuve d’une capacité exceptionnelle de mobilisation de ressources durant l’année 2023. En effet, 14, 2 milliards FCFA ont été mobilisés à travers la mise en place de 09 nouveaux projets financés avec l’appui des partenaires au développement notamment l’Agence Française de Développement, la Banque Mondiale, l’Union Européenne, les coopérations allemandes et luxembourgeoise, l’Ambassade de France, le19M de la maison Chanel, Fonds National de développement agricole (FIDA), soit un taux de 49,8% sur le montant prévisionnel de la CFCE en 2023.\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gg0bSSONa6w"
      },
      "outputs": [],
      "source": [
        "# # Rechercher les documents les plus proches\n",
        "# query = \"c'est quoi un pole emploie?\" #Une question sur le document\n",
        "# retrieved_docs = vector_store.similarity_search(query, k=3)\n",
        "\n",
        "# # Afficher les documents récupérés\n",
        "# for doc in retrieved_docs:\n",
        "#     print(doc.page_content)\n",
        "#     print(\"------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpwRyTY6Na6x"
      },
      "source": [
        "### 2. Le Module de Génération (Generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaC0j_eiNa6x"
      },
      "source": [
        "Le module de génération est responsable de produire une réponse cohérente et contextuellement appropriée en se basant sur les documents récupérés par le retriever."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDXpgGlgNa6x"
      },
      "source": [
        "**Fonctionnement du Generator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV1kYemmNa6x"
      },
      "source": [
        "1. **Préparation du contexte** : Les documents récupérés par le retriever sont concaténés en un seul bloc.\n",
        "\n",
        "2. **Construction du prompt** : Structuration du prompt pour donner du contexte au LLM.\n",
        "\n",
        "3. **Génération de réponse** : Utilisation d’un LLM pour formuler une réponse en s’appuyant sur le contexte.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhRSMLJ9Na6x",
        "outputId": "3be57276-d33c-4b29-8aeb-2e782cfd4465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le Fonds de Financement de la Formation professionnelle et technique (3FPT) a mené une variété de projets en 2023, s'appuyant sur des initiatives lancées entre 2019 et 2023.  Ces projets couvrent un large spectre d'actions visant à améliorer les qualifications professionnelles et l'insertion professionnelle des jeunes.\n",
            "\n",
            "On peut notamment citer :\n",
            "\n",
            "* **Des investissements dans des infrastructures et équipements:**  75 projets d'investissements (et 2 avenants) ont été soutenus.\n",
            "* **Des plans stratégiques de développement:**  30 plans stratégiques ont été financés pour améliorer la planification et l'efficacité des formations.\n",
            "* **Des projets de formation et d'insertion professionnelle:** 82 projets ont été mis en œuvre, dont 27 intégraient un volet investissement.  Ceci souligne l'importance donnée à la fois à la formation et à l'accompagnement vers l'emploi.\n",
            "* **Des formations de formateurs:** 23 projets ont été dédiés à la formation des enseignants et des formateurs, un élément clé pour garantir la qualité de l'enseignement.\n",
            "* **Des contrats de projets de formation qualifiante pour les jeunes:**  106 contrats ont été signés, témoignant d'un engagement important envers l'emploi des jeunes.  Le 3FPT s'est fixé comme objectif de former au moins 2600 jeunes sur trois ans dans le cadre de ces projets.\n",
            "\n",
            "Les secteurs d'activité concernés par ces formations sont variés,  incluant le multimédia, l'administration de réseaux, le tourisme et les loisirs, les métiers du rail, et la gestion et l'exploitation minières.  Ce large éventail de domaines montre la volonté du 3FPT de répondre aux besoins d'un marché du travail diversifié.\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "# Charger le modèle de génération\n",
        "llm_model = \"gemini-1.5-flash\"\n",
        "chat_model = ChatGoogleGenerativeAI(model=llm_model, api_key=API_KEY)\n",
        "\n",
        "\n",
        "# Créer le prompt avec le contexte récupéré\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "prompt = f\"Document : {context}\\n\\nQuestion : {query}\\nRéponse détaillée :\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\n",
        "        \"Tu es Afdel, un assistant virtuel raffiné et perspicace, doté d’une éloquence naturelle. \"\n",
        "        \"Tu réponds avec clarté, élégance et spontanéité, en t’appuyant sur les informations issues des documents fournis. \"\n",
        "        \"Ta mission est d’offrir des réponses pertinentes et nuancées, reformulées avec tes propres mots pour une meilleure compréhension. \"\n",
        "        \"Ton ton est chaleureux, engageant et professionnel, sans jamais citer tes sources explicitement. \"\n",
        "        \"Tu adaptes ton style en fonction du contexte et de ton interlocuteur, avec une touche d’intelligence et de finesse.\"\n",
        "    ),\n",
        "    HumanMessage(content=prompt)\n",
        "]\n",
        "\n",
        "\n",
        "# Générer la réponse\n",
        "response = chat_model(messages)\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chemin_dir = \"/content/drive/MyDrive/MES COURS/L3/ChatBot/Faiss\"\n",
        "\n",
        "# Sauvegarder la base de données vectorielle FAISS\n",
        "vector_store.save_local(chemin_dir)\n",
        "\n",
        "# Charger ultérieurement la base de données vectorielle\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Activer la désérialisation dangereuse en toute sécurité si vous avez créé le fichier\n",
        "vector_store = FAISS.load_local(\n",
        "    chemin_dir,\n",
        "    embedding_model,\n",
        "    allow_dangerous_deserialization=True  # Autorisation explicite\n",
        ")\n",
        "print\n"
      ],
      "metadata": {
        "id": "jImuZtCNyJLd"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}